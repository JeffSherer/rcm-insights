"""
Local RAG chatbot over claims KPIs.
Run:  python ai/agent_rag.py
"""

import os
import pandas as pd
import faiss
from sentence_transformers import SentenceTransformer
from langchain.llms import OpenAI
from langchain.chains import RetrievalQA
from langchain.vectorstores import FAISS
import snowflake.connector as sf

# â”€â”€ 1â€†connect to Snowflake and pull KPI view â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
conn = sf.connect(
    user="YOUR_USER",
    password="YOUR_PASSWORD",
    account="YOUR_ACCOUNT",
    warehouse="YOUR_WAREHOUSE",
    database="RCM_LAB",
    schema="PUBLIC",
)
kpi_df = pd.read_sql("select * from v_claims_kpis order by claim_month", conn)

# â”€â”€ 2â€†turn each row into a plain-text doc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
docs = [
    f"In {row.claim_month:%Y-%m}, total claims were {row.total_claims}"
    for row in kpi_df.itertuples()
]

# â”€â”€ 3â€†embed and index with FAISS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
embedder = SentenceTransformer("all-MiniLM-L6-v2")
embeddings = embedder.encode(docs)
index = faiss.IndexFlatL2(embeddings.shape[1])
index.add(embeddings)
vector_store = FAISS(index, docs)

# â”€â”€ 4â€†wire up Retrieval-QA with OpenAI (or another LLM) â”€
qa = RetrievalQA.from_chain_type(
    llm=OpenAI(temperature=0.0),
    chain_type="stuff",
    retriever=vector_store.as_retriever()
)

# â”€â”€ 5â€†simple CLI loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("RAG chatbot ready. Ask about monthly claim volume.")
while True:
    q = input("ðŸ¡† ")
    if q.lower() in {"exit", "quit"}:
        break
    print(qa.run(q))
